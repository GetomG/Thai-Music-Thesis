{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "source": [
        "# Thai Classical Music Motif Analysis â€“ Proof of Concept (Desc)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "Lb8dIaongolX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\n",
        "## 1. Data Loading & Corpus Overview\n",
        "- Load JSON / MIDI-derived symbolic data  \n",
        "- Basic stats (songs per motif, bars per song)\n",
        "\n",
        "## 2. Symbolic Normalization\n",
        "- Note vocabulary definition\n",
        "- Rest handling\n",
        "- Octave / ornament normalization\n",
        "- Sequence flattening (bar â†’ token stream)\n",
        "\n",
        "## 3. Feature Extraction\n",
        "### 3.1 Note-Level Statistics\n",
        "- Pitch histogram\n",
        "- Interval distribution\n",
        "\n",
        "### 3.2 N-gram Extraction\n",
        "- Unigram / Bigram / Trigram counts\n",
        "- Per-motif aggregation\n",
        "\n",
        "### 3.3 Contour Representation (optional)\n",
        "- Up / Down / Same encoding\n",
        "- Contour n-grams\n",
        "\n",
        "## 4. Motif Similarity Analysis\n",
        "- Feature vector construction\n",
        "- Cosine / KL similarity\n",
        "- Song-to-song and motif-level similarity\n",
        "\n",
        "## 5. Motif Classification (Baseline)\n",
        "- Train / validation split\n",
        "- Linear models (LogReg / SVM)\n",
        "- Confusion matrix & accuracy\n",
        "\n",
        "## 6. Visualization\n",
        "- N-gram heatmaps\n",
        "- PCA / UMAP motif clustering\n",
        "\n",
        "## 7. Discussion (Preliminary Findings)\n",
        "- Observed motif patterns\n",
        "- Limitations (small data, single layer)\n",
        "- Implications for Stage 2 tagging\n",
        "\n",
        "## 8. Next Steps\n",
        "- Dataset expansion\n",
        "- Audio features (MFCC / chroma)\n",
        "- Conditional generation pipeline\n"
      ],
      "metadata": {
        "id": "CqbzEPGCXZsZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "#\n"
      ],
      "metadata": {
        "id": "8EP_QaPMXllY"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# Thai Classical Music Motif Analysis â€“ Code\n"
      ],
      "metadata": {
        "id": "FxXN3op5Xpns"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 0. Environment Setup (once per runtime)\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "phmt-WELXIY2"
      }
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qPe8fdy5Er2J",
        "outputId": "3e2d6834-36e3-4480-ffc4-5df16862a42c"
      },
      "outputs": [],
      "source": [
        "!pip install mido python-rtmidi"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!wget https://github.com/Phonbopit/sarabun-webfont/raw/master/fonts/thsarabunnew-webfont.ttf\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "collapsed": true,
        "id": "-wtSprU7H8Ap",
        "outputId": "e62c5e37-eae3-4651-f823-337a7d6299b9"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone https://github.com/GetomG/Thai-Music-Thesis.git\n",
        "# If already cloned:\n",
        "# !git pull"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R8qqgwg90NAb",
        "outputId": "73e5c514-04ff-4b55-e38f-196dedd44197"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Enter project folder\n",
        "%cd Thai-Music-Thesis"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "pFcKH10g0RfP",
        "outputId": "afdcf985-c1dd-4235-88ca-cab9c87260cf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib as mpl\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "mpl.font_manager.fontManager.addfont('thsarabunnew-webfont.ttf')\n",
        "mpl.rc('font', family='TH Sarabun New')\n",
        "mpl.rcParams[\"axes.unicode_minus\"] = False"
      ],
      "metadata": {
        "id": "rs7JkrIrgGYO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/drive')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iglAa2SAFtDS",
        "outputId": "3bd8bcbc-3884-4202-e45d-6dc16e29cde6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Helpers Libs\n"
      ],
      "metadata": {
        "id": "9fix8Xvy0Xoe"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ============================================================\n",
        "# 2. I/O Utilities\n",
        "# ============================================================\n",
        "from thai_music_utils.io_utils import (\n",
        "    save_json_bar_per_line\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# 3. Notation Processing\n",
        "# - Flatten JSON â†’ tokens\n",
        "# - Normalize octave markers\n",
        "# - Convert to continuous sequence string\n",
        "# ============================================================\n",
        "from thai_music_utils.notation_utils import (\n",
        "    flatten_song_notation,\n",
        "    normalize_octave_markers,\n",
        "    notation_to_sequence\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# 4. Octave Inference (DP-based register guessing)\n",
        "# ============================================================\n",
        "from thai_music_utils.octave_inference import (\n",
        "    is_thai_note,\n",
        "    get_fixed_octave,\n",
        "    guess_octaves_with_constraints,\n",
        "    add_octaves_respecting_labels\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# 5. Preprocessing Utilities\n",
        "# ============================================================\n",
        "from thai_music_utils.preprocessing import (\n",
        "    flatten_song_data,\n",
        "    remove_all_signs\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# 6. MIDI Rendering (Ranad-specific)\n",
        "# ============================================================\n",
        "from thai_music_utils.midi_ranad import (\n",
        "    generate_ranad_midi\n",
        ")\n",
        "\n",
        "# ============================================================\n",
        "# 7. EDA Helpers (Symbolic Analysis)\n",
        "# ============================================================\n",
        "from thai_music_utils.eda_symbolic_normalization import (\n",
        "    normalize_token,\n",
        "    normalize_bar,\n",
        "    flatten_song,\n",
        "    THAI_NOTES,\n",
        "    UP_MARK,\n",
        "    LOW_MARK,\n",
        "    REST_TOKEN\n",
        ")\n",
        "\n",
        "from thai_music_utils.eda_stats import (\n",
        "    extract_symbols,\n",
        "    pitch_stats,\n",
        "    stats_to_df\n",
        ")"
      ],
      "metadata": {
        "id": "mLpAU18E0aqY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 1. Data Loading & Corpus Overview\n",
        "- Load JSON / MIDI-derived symbolic data  \n",
        "- Basic stats (songs per motif, bars per song)\n"
      ],
      "metadata": {
        "id": "l_wkaOvGHpz_"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import json\n",
        "from pathlib import Path\n",
        "from collections import defaultdict\n",
        "\n",
        "BASE = Path(\"/content/drive/MyDrive/thai_music_data/songs\")\n",
        "\n",
        "songs = []\n",
        "\n",
        "for motif_dir in BASE.iterdir():\n",
        "    if not motif_dir.is_dir():\n",
        "        continue\n",
        "\n",
        "    motif = motif_dir.name\n",
        "\n",
        "    for song_dir in motif_dir.iterdir():\n",
        "        json_dir = song_dir / \"json\"\n",
        "        if not json_dir.exists():\n",
        "            continue\n",
        "\n",
        "        for json_file in json_dir.glob(\"*.json\"):\n",
        "            try:\n",
        "                with open(json_file, \"r\", encoding=\"utf-8\") as f:\n",
        "                    data = json.load(f)\n",
        "\n",
        "                songs.append({\n",
        "                    \"motif\": motif,\n",
        "                    \"song\": song_dir.name,\n",
        "                    \"path\": str(json_file),\n",
        "                    \"data\": data\n",
        "                })\n",
        "\n",
        "            except Exception as e:\n",
        "                print(f\"âš ï¸ Skipped {json_file}: {e}\")"
      ],
      "metadata": {
        "id": "qNobW3nHHr0p"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(f\"Total songs loaded: {len(songs)}\")\n",
        "\n",
        "by_motif = defaultdict(int)\n",
        "for s in songs:\n",
        "    by_motif[s[\"motif\"]] += 1\n",
        "\n",
        "for motif, n in by_motif.items():\n",
        "    print(f\"{motif}: {n} songs\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "mKRRWM4JQncu",
        "outputId": "cbd150e1-1b68-4f28-9005-548a5058d497"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from pathlib import Path\n",
        "\n",
        "BASE = Path(\"/content/drive/MyDrive/thai_music_data/songs\")\n",
        "\n",
        "for motif_dir in BASE.iterdir():\n",
        "    if not motif_dir.is_dir():\n",
        "        continue\n",
        "\n",
        "    for song_dir in motif_dir.iterdir():\n",
        "        json_dir = song_dir / \"json\"\n",
        "        if not json_dir.exists():\n",
        "            continue\n",
        "\n",
        "        json_files = sorted(p.name for p in json_dir.glob(\"*.json\"))\n",
        "        if not json_files:\n",
        "            continue\n",
        "\n",
        "        print(f\"{motif_dir.name}/{song_dir.name}:\")\n",
        "        for jf in json_files:\n",
        "            print(f\"  - {jf}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4f5r1pnjSe0_",
        "outputId": "a104314c-8727-4da5-abca-b760c2b7414e",
        "collapsed": true
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 2. Symbolic Normalization (preprocessing)\n",
        "- Note vocabulary definition\n",
        "- Rest handling\n",
        "- Octave / ornament normalization\n",
        "- Sequence flattening (bar â†’ token stream)\n"
      ],
      "metadata": {
        "id": "HCyVTfTHHQR9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ----------------------------\n",
        "# Apply normalization to corpus\n",
        "# ----------------------------\n",
        "for s in songs:\n",
        "    try:\n",
        "        # Store normalized symbolic sequence WITHOUT overwriting raw data\n",
        "        s[\"sequence\"] = flatten_song(s[\"data\"])\n",
        "    except Exception as e:\n",
        "        # Fault-tolerant: broken JSON â†’ empty sequence\n",
        "        print(f\"âš ï¸ Normalization failed for {s['song']}: {e}\")\n",
        "        s[\"sequence\"] = []\n",
        "\n",
        "\n",
        "# ----------------------------\n",
        "# Sanity check (inspect output)\n",
        "# ----------------------------\n",
        "songs[29][\"sequence\"][:40]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hGyYWBJPUoBu",
        "outputId": "11c97051-e186-446e-e2bc-2d1774f27b77"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3. Feature Extraction\n",
        "\n"
      ],
      "metadata": {
        "id": "q47f-6aWVF1A"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.1 Note-Level Statistics\n",
        "- Pitch histogram\n",
        "- Interval distribution\n"
      ],
      "metadata": {
        "id": "6DeK07hU6pA5"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.1 Pitch / Symbol Histogram\n",
        "We want to know which notes are used and how often.\n",
        "- Count how often à¸”, à¸”à¹, à¸‹à¸º, etc. appear\n",
        "#### This tells us:\n",
        "- register preference (high / low)\n",
        "- stylistic bias per motif\n",
        "- We split compound tokens like à¸‹à¸¥à¸”à¹à¸¥ into individual notes\n",
        "- Rests are ignored\n"
      ],
      "metadata": {
        "id": "UfzFWx94VmBM"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# With octave information\n",
        "pitch_with_octave = pitch_stats(songs, strip_octave=False)\n",
        "df_pitch_with_octave = stats_to_df(pitch_with_octave)\n",
        "\n",
        "# Without octave information\n",
        "pitch_no_octave = pitch_stats(songs, strip_octave=True)\n",
        "df_pitch_no_octave = stats_to_df(pitch_no_octave)"
      ],
      "metadata": {
        "id": "VBJFZiOoyRud"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pitch_no_octave[\"à¸¥à¸²à¸§\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "1PrS_FUAWhKN",
        "outputId": "4b598341-2196-49cd-d60d-cfd55481baed"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pitch_no_octave[\"à¹à¸‚à¸\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "BpEfB108Wore",
        "outputId": "8a5e497e-cbe8-4cee-df07-8672f768a038"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pitch_no_octave[\"à¹€à¸‚à¸¡à¸£\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "QYyztnDRXitS",
        "outputId": "1052b906-1a98-45a5-f206-25541017a3e1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_pitch_no_octave[\"à¸žà¸¡à¹ˆà¸²\"]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 269
        },
        "id": "9LtX_XBjyuR0",
        "outputId": "99c4fc3c-8fae-444c-db06-831d0bb7ac51"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.1.2 Interval Distribution\n"
      ],
      "metadata": {
        "id": "71ntbyKuX21B"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PITCH_ORDER = {\n",
        "    \"à¸‹à¸º\": -3, \"à¸¥à¸º\": -2, \"à¸—à¸º\": -1,\n",
        "    \"à¸”\": 0, \"à¸£\": 1, \"à¸¡\": 2, \"à¸Ÿ\": 3, \"à¸‹\": 4, \"à¸¥\": 5, \"à¸—\": 6,\n",
        "    \"à¸”à¹\": 7, \"à¸£à¹\": 8, \"à¸¡à¹\": 9, \"à¸Ÿà¹\": 10, \"à¸‹à¹\": 11, \"à¸¥à¹\": 12,\n",
        "}"
      ],
      "metadata": {
        "id": "7k3rD8JpX8tm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def interval_bins(intervals):\n",
        "    bins = {\n",
        "        \"Down step (-1)\": 0,\n",
        "        \"Same (0)\": 0,\n",
        "        \"Up step (+1)\": 0,\n",
        "        \"Medium jump (2â€“3)\": 0,\n",
        "        \"Large leap (â‰¥4)\": 0\n",
        "    }\n",
        "\n",
        "    for iv in intervals:\n",
        "        if iv == -1:\n",
        "            bins[\"Down step (-1)\"] += 1\n",
        "        elif iv == 0:\n",
        "            bins[\"Same (0)\"] += 1\n",
        "        elif iv == 1:\n",
        "            bins[\"Up step (+1)\"] += 1\n",
        "        elif abs(iv) in (2, 3):\n",
        "            bins[\"Medium jump (2â€“3)\"] += 1\n",
        "        elif abs(iv) >= 4:\n",
        "            bins[\"Large leap (â‰¥4)\"] += 1\n",
        "\n",
        "    return bins"
      ],
      "metadata": {
        "id": "PrtYywo42-n2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_intervals(sequence):\n",
        "    \"\"\"\n",
        "    Convert a symbolic sequence into signed pitch intervals\n",
        "    using the PITCH_ORDER dict.\n",
        "    \"\"\"\n",
        "    symbols = extract_symbols(sequence)\n",
        "    intervals = []\n",
        "\n",
        "    for a, b in zip(symbols, symbols[1:]):\n",
        "        if a in PITCH_ORDER and b in PITCH_ORDER:\n",
        "            intervals.append(PITCH_ORDER[b] - PITCH_ORDER[a])\n",
        "\n",
        "    return intervals"
      ],
      "metadata": {
        "id": "-tpXA_eu_-oS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "interval_bin_pct_by_motif = {}\n",
        "\n",
        "for motif in {s[\"motif\"] for s in songs}:\n",
        "    all_intervals = []\n",
        "    for s in songs:\n",
        "        if s[\"motif\"] == motif:\n",
        "            all_intervals.extend(extract_intervals(s[\"sequence\"]))\n",
        "\n",
        "    bins = interval_bins(all_intervals)\n",
        "    total = sum(bins.values())\n",
        "\n",
        "    interval_bin_pct_by_motif[motif] = {\n",
        "        k: (v / total * 100 if total else 0)\n",
        "        for k, v in bins.items()\n",
        "    }"
      ],
      "metadata": {
        "id": "vpZy0j5P2_gU"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_grouped_vertical(interval_bin_pct_by_motif, title):\n",
        "\n",
        "    motifs = list(interval_bin_pct_by_motif.keys())\n",
        "    bins = list(next(iter(interval_bin_pct_by_motif.values())).keys())\n",
        "\n",
        "    n_bins = len(bins)\n",
        "    n_motifs = len(motifs)\n",
        "\n",
        "    bar_width = 0.12   # ðŸ”¥ MUCH thinner\n",
        "    x = np.arange(n_bins) * 1.1   # ðŸ”¥ add spacing between groups\n",
        "\n",
        "    colors = plt.get_cmap(\"Set3\").colors  # cleaner palette\n",
        "\n",
        "    plt.figure(figsize=(14, 6))  # ðŸ”¥ wider figure\n",
        "\n",
        "    for i, motif in enumerate(motifs):\n",
        "        values = [interval_bin_pct_by_motif[motif][b] for b in bins]\n",
        "\n",
        "        plt.bar(\n",
        "            x + i * bar_width,\n",
        "            values,\n",
        "            width=bar_width,\n",
        "            label=motif,\n",
        "            color=colors[i],\n",
        "            edgecolor=\"black\",\n",
        "            linewidth=0.4\n",
        "        )\n",
        "\n",
        "    plt.xticks(\n",
        "        x + bar_width * (n_motifs - 1) / 2,\n",
        "        bins,\n",
        "        rotation=30\n",
        "    )\n",
        "\n",
        "    plt.ylabel(\"Percentage (%)\")\n",
        "    plt.title(title)\n",
        "    plt.legend(frameon=False)\n",
        "    plt.grid(axis=\"y\", linestyle=\"--\", alpha=0.3)\n",
        "\n",
        "    plt.tight_layout()\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "2-lc7PNe9_HY"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "plot_grouped_vertical(\n",
        "    interval_bin_pct_by_motif,\n",
        "    \"Interval Jump Distribution (%) â€“ Motif Comparison\"\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 456
        },
        "id": "hSvocuLf-BfN",
        "outputId": "a53d3033-94db-43bd-afbe-fd4a922246ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "rows = []\n",
        "\n",
        "for motif, pct_bins in interval_bin_pct_by_motif.items():\n",
        "    rows.append({\n",
        "        \"motif\": motif,\n",
        "        \"stepwise_%\": (\n",
        "            pct_bins[\"Down step (-1)\"]\n",
        "            + pct_bins[\"Same (0)\"]\n",
        "            + pct_bins[\"Up step (+1)\"]\n",
        "        ),\n",
        "        \"medium_%\": pct_bins[\"Medium jump (2â€“3)\"],\n",
        "        \"large_%\": pct_bins[\"Large leap (â‰¥4)\"],\n",
        "    })\n",
        "\n",
        "df_interval_bins = (\n",
        "    pd.DataFrame(rows)\n",
        "    .sort_values(\"motif\")\n",
        "    .reset_index(drop=True)\n",
        ")\n",
        "\n",
        "df_interval_bins = df_interval_bins.round(2)\n",
        "\n",
        "df_interval_bins"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 238
        },
        "id": "toOATMoL44zZ",
        "outputId": "b1d9ea72-41a5-4204-eff2-55f4393c4ef3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 3.2 N-grams\n"
      ],
      "metadata": {
        "id": "sI0_6Xpp6c6X"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.1 Symbol sequence construction\n",
        "- We take each song and turn it into one linear sequence of symbols that n-grams can operate on.\n",
        "\n",
        "- Future work may incorporate rest-aware segmentation, where extended rests are treated as phrase boundaries rather than melodic tokens.\n"
      ],
      "metadata": {
        "id": "EAP045W87hbG"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def song_to_symbol_sequence(song, strip_octave=True):\n",
        "    \"\"\"\n",
        "    Convert a song dict into a flat sequence of note symbols.\n",
        "    \"\"\"\n",
        "    sequence = song[\"sequence\"]  # already flattened bars\n",
        "    symbols = extract_symbols(sequence, strip_octave=strip_octave)\n",
        "    return symbols"
      ],
      "metadata": {
        "id": "1WpBywj17idC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "s = songs[0]\n",
        "seq = song_to_symbol_sequence(s)\n",
        "seq[:30]"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LZrKMuE16ebw",
        "outputId": "1443c0d6-5f62-456e-ce84-d996a5148ff8"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for s in songs:\n",
        "    s[\"symbol_sequence\"] = song_to_symbol_sequence(s)"
      ],
      "metadata": {
        "id": "rznKBc1r7ma5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "songs[0][\"motif\"], len(songs[0][\"symbol_sequence\"])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FIgN0lF47-WB",
        "outputId": "4488e27b-6725-4ed6-a1c1-113fc5e4429d"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.2 Unigram Statistics (same as hist above)\n",
        "\n",
        "- probably the same as histogram above\n",
        "\n",
        "- This provides a baseline representation of melodic vocabulary and serves as a consistency check before moving to higher-order n-grams.\n"
      ],
      "metadata": {
        "id": "Q6eji7_I8GhX"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.3 Bigram Statistics\n",
        "\n",
        "- Bigram statistics count the frequency of consecutive pairs of note symbols in the symbolic sequence.\n",
        "\n",
        "- This captures local melodic transition patterns and provides insight into motif-specific note-to-note grammar beyond individual pitch usage.\n"
      ],
      "metadata": {
        "id": "p5HZTbeW9ccu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def extract_bigrams(symbol_sequence):\n",
        "    \"\"\"\n",
        "    Convert a symbol sequence into bigrams.\n",
        "    Example: ['à¸”','à¸£','à¸¡'] -> [('à¸”','à¸£'), ('à¸£','à¸¡')]\n",
        "    \"\"\"\n",
        "    return zip(symbol_sequence, symbol_sequence[1:])"
      ],
      "metadata": {
        "id": "fXbfP-x79eTD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "bigram_counts_by_motif = {}\n",
        "\n",
        "for motif in {s[\"motif\"] for s in songs}:\n",
        "    counter = Counter()\n",
        "\n",
        "    for s in songs:\n",
        "        if s[\"motif\"] == motif:\n",
        "            counter.update(extract_bigrams(s[\"symbol_sequence\"]))\n",
        "\n",
        "    bigram_counts_by_motif[motif] = counter"
      ],
      "metadata": {
        "id": "B1-YOZsl9jCV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_bigram_by_motif = {}\n",
        "\n",
        "for motif, counter in bigram_counts_by_motif.items():\n",
        "    total = sum(counter.values())\n",
        "\n",
        "    df = (\n",
        "        pd.DataFrame([\n",
        "            {\n",
        "                \"bigram\": f\"{a}â†’{b}\",\n",
        "                \"count\": cnt,\n",
        "                \"percent\": cnt / total * 100\n",
        "            }\n",
        "            for (a, b), cnt in counter.items()\n",
        "        ])\n",
        "        .sort_values(\"count\", ascending=False)\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    df_bigram_by_motif[motif] = df"
      ],
      "metadata": {
        "id": "nHuqBOmD9m12"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_topk_side_by_side(df_bigram_by_motif, top_k=15):\n",
        "\n",
        "    merged = pd.DataFrame()\n",
        "\n",
        "    for motif, df in df_bigram_by_motif.items():\n",
        "        top = df.head(top_k).copy()\n",
        "        top = top[[\"bigram\", \"percent\"]]\n",
        "\n",
        "        # round to 2 decimal places\n",
        "        top[\"percent\"] = top[\"percent\"].round(2)\n",
        "\n",
        "        top.columns = [\n",
        "            f\"{motif}_bigram\",\n",
        "            f\"{motif}_%\"\n",
        "        ]\n",
        "\n",
        "        merged = pd.concat([merged, top], axis=1)\n",
        "\n",
        "    return merged\n",
        "\n",
        "\n",
        "merged_df = merge_topk_side_by_side(df_bigram_by_motif, top_k=15)\n",
        "merged_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 537
        },
        "id": "lFjqpfywNOQR",
        "outputId": "8cc2eacb-94bf-4b49-d76e-7ca26fba0207"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.4 Trigram Statistics\n",
        "\n",
        "- Trigram statistics count the frequency of three consecutive note symbols in the symbolic sequence.\n",
        "\n",
        "- Trigrams capture short melodic phrases and local contour patterns, which are often more distinctive of motif style than single notes or pairwise transitions.\n"
      ],
      "metadata": {
        "id": "QRyXghUO-iq1"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def extract_trigrams(symbol_sequence):\n",
        "    \"\"\"\n",
        "    Convert a symbol sequence into trigrams.\n",
        "    Example: ['à¸”','à¸£','à¸¡','à¸‹'] -> [('à¸”','à¸£','à¸¡'), ('à¸£','à¸¡','à¸‹')]\n",
        "    \"\"\"\n",
        "    return zip(symbol_sequence, symbol_sequence[1:], symbol_sequence[2:])"
      ],
      "metadata": {
        "id": "Vu-hzXPP-ifu"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "trigram_counts_by_motif = {}\n",
        "\n",
        "for motif in {s[\"motif\"] for s in songs}:\n",
        "    counter = Counter()\n",
        "\n",
        "    for s in songs:\n",
        "        if s[\"motif\"] == motif:\n",
        "            counter.update(extract_trigrams(s[\"symbol_sequence\"]))\n",
        "\n",
        "    trigram_counts_by_motif[motif] = counter"
      ],
      "metadata": {
        "id": "CpFPg-pB-GNs"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_trigram_by_motif = {}\n",
        "\n",
        "for motif, counter in trigram_counts_by_motif.items():\n",
        "    total = sum(counter.values())\n",
        "\n",
        "    df = (\n",
        "        pd.DataFrame([\n",
        "            {\n",
        "                \"trigram\": f\"{a}â†’{b}â†’{c}\",\n",
        "                \"count\": cnt,\n",
        "                \"percent\": cnt / total * 100\n",
        "            }\n",
        "            for (a, b, c), cnt in counter.items()\n",
        "        ])\n",
        "        .sort_values(\"count\", ascending=False)\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    df_trigram_by_motif[motif] = df"
      ],
      "metadata": {
        "id": "A9pOgbPa-sRL"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_topk_trigram_side_by_side(df_trigram_by_motif, top_k=15):\n",
        "\n",
        "    merged = pd.DataFrame()\n",
        "\n",
        "    for motif, df in df_trigram_by_motif.items():\n",
        "        top = df.head(top_k).copy()\n",
        "        top = top[[\"trigram\", \"percent\"]]\n",
        "\n",
        "        # round to 2 decimals\n",
        "        top[\"percent\"] = top[\"percent\"].round(2)\n",
        "\n",
        "        top.columns = [\n",
        "            f\"{motif}_trigram\",\n",
        "            f\"{motif}_%\"\n",
        "        ]\n",
        "\n",
        "        merged = pd.concat([merged, top], axis=1)\n",
        "\n",
        "    return merged\n",
        "\n",
        "\n",
        "merged_trigram_df = merge_topk_trigram_side_by_side(df_trigram_by_motif, top_k=15)\n",
        "merged_trigram_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "ZYQaPTJOOE7R",
        "outputId": "7542b60d-2710-4465-a2e1-54afaa9cff3e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 3.2.5 Quadgram Statistics\n"
      ],
      "metadata": {
        "id": "00gXGFVpOhms"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from collections import Counter\n",
        "\n",
        "def extract_quadgrams(symbol_sequence):\n",
        "    \"\"\"\n",
        "    Convert a symbol sequence into quadgrams.\n",
        "    Example: ['à¸”','à¸£','à¸¡','à¸‹','à¸¥']\n",
        "    -> [('à¸”','à¸£','à¸¡','à¸‹'), ('à¸£','à¸¡','à¸‹','à¸¥')]\n",
        "    \"\"\"\n",
        "    return zip(\n",
        "        symbol_sequence,\n",
        "        symbol_sequence[1:],\n",
        "        symbol_sequence[2:],\n",
        "        symbol_sequence[3:]\n",
        "    )"
      ],
      "metadata": {
        "id": "EM6UiLZaOmqH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "quadgram_counts_by_motif = {}\n",
        "\n",
        "for motif in {s[\"motif\"] for s in songs}:\n",
        "    counter = Counter()\n",
        "\n",
        "    for s in songs:\n",
        "        if s[\"motif\"] == motif:\n",
        "            counter.update(extract_quadgrams(s[\"symbol_sequence\"]))\n",
        "\n",
        "    quadgram_counts_by_motif[motif] = counter"
      ],
      "metadata": {
        "id": "PmF1RrSCOni3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "df_quadgram_by_motif = {}\n",
        "\n",
        "for motif, counter in quadgram_counts_by_motif.items():\n",
        "    total = sum(counter.values())\n",
        "\n",
        "    df = (\n",
        "        pd.DataFrame([\n",
        "            {\n",
        "                \"quadgram\": f\"{a}â†’{b}â†’{c}â†’{d}\",\n",
        "                \"count\": cnt,\n",
        "                \"percent\": cnt / total * 100\n",
        "            }\n",
        "            for (a, b, c, d), cnt in counter.items()\n",
        "        ])\n",
        "        .sort_values(\"count\", ascending=False)\n",
        "        .reset_index(drop=True)\n",
        "    )\n",
        "\n",
        "    df_quadgram_by_motif[motif] = df"
      ],
      "metadata": {
        "id": "wfAM8XC9OqBf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def merge_topk_quadgram_side_by_side(df_quadgram_by_motif, top_k=15):\n",
        "\n",
        "    merged = pd.DataFrame()\n",
        "\n",
        "    for motif, df in df_quadgram_by_motif.items():\n",
        "        top = df.head(top_k).copy()\n",
        "        top = top[[\"quadgram\", \"percent\"]]\n",
        "\n",
        "        top[\"percent\"] = top[\"percent\"].round(2)\n",
        "\n",
        "        top.columns = [\n",
        "            f\"{motif}_quadgram\",\n",
        "            f\"{motif}_%\"\n",
        "        ]\n",
        "\n",
        "        merged = pd.concat([merged, top], axis=1)\n",
        "\n",
        "    return merged\n",
        "\n",
        "\n",
        "merged_quad_df = merge_topk_quadgram_side_by_side(df_quadgram_by_motif, top_k=15)\n",
        "merged_quad_df"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 557
        },
        "id": "AYwZ7CYJOsEu",
        "outputId": "e25f7eaf-b868-4720-eacf-f1b1bff5eae6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Motif Similarity Analysis â€“ Feature Vector\n"
      ],
      "metadata": {
        "id": "0Caelg5hG8LP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### 4.1 Feature Vector ð’› construction\n",
        "\n",
        "Each motif is represented by a fixed-dimensional feature vector ð’› that summarizes its symbolic melodic characteristics.\n",
        "\n",
        "- The first part of ð’› encodes the octave-agnostic pitch distribution (à¸”, à¸£, à¸¡, à¸Ÿ, à¸‹, à¸¥, à¸—), capturing melodic vocabulary preferences.\n",
        "- The second part of ð’› encodes interval magnitude statistics (stepwise, medium, large), capturing characteristic melodic motion patterns.\n",
        "\n",
        "This compact representation enables direct quantitative comparison between motifs using standard similarity measures.\n",
        "\n",
        "\n",
        "\t1.\tDirectional interval stats (up / down / same)  â†’ +3D\n",
        "\t2.\tInterval entropy â†’ +1D\n",
        "\t3.\tPitch-class entropy â†’ +1D\n",
        "\t4.\tTop-K pitch bigram frequencies â†’ +K D (weâ€™ll keep K small, e.g. 5â€“10)\n",
        "\n"
      ],
      "metadata": {
        "id": "OgjH2q3cHG1T"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "PITCH_ORDER = [\"à¸”\", \"à¸£\", \"à¸¡\", \"à¸Ÿ\", \"à¸‹\", \"à¸¥\", \"à¸—\"]"
      ],
      "metadata": {
        "id": "zX3LcIYCHFfw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# build pitch vector per motif (7D)\n",
        "\n",
        "def pitch_vector_from_df(df):\n",
        "    \"\"\"\n",
        "    Convert pitch DataFrame into a fixed-order vector.\n",
        "    Missing notes get 0.\n",
        "    \"\"\"\n",
        "    pitch_map = dict(zip(df[\"note\"], df[\"percent\"]))\n",
        "    return [pitch_map.get(n, 0.0) for n in PITCH_ORDER]\n",
        "\n",
        "# build interval vector per motif (3D)\n",
        "def interval_vector_from_df(df_interval_bins, motif):\n",
        "    row = df_interval_bins[df_interval_bins[\"motif\"] == motif].iloc[0]\n",
        "    return [\n",
        "        row[\"stepwise_%\"],\n",
        "        row[\"medium_%\"],\n",
        "        row[\"large_%\"]\n",
        "    ]"
      ],
      "metadata": {
        "id": "DnJ-mofnHYZF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "motif_vectors = {}\n",
        "\n",
        "for motif in df_interval_bins[\"motif\"]:\n",
        "    pitch_vec = pitch_vector_from_df(df_pitch_no_octave[motif])\n",
        "    interval_vec = interval_vector_from_df(df_interval_bins, motif)\n",
        "\n",
        "    motif_vectors[motif] = np.array(pitch_vec + interval_vec)"
      ],
      "metadata": {
        "id": "Gb43dZXxHldd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "*Each* motif is now a point in 10D space:\n",
        "\n",
        "\t- dimensions 1â€“7 â†’ what notes are used\n",
        "\t- dimensions 8â€“10 â†’ how melodies move\n",
        "\n",
        "Similarity = closeness in this space.\n"
      ],
      "metadata": {
        "id": "RgF_vJRxHpXu"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "motif_vectors[\"à¸¥à¸²à¸§\"], motif_vectors[\"à¸¥à¸²à¸§\"].shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9XgLWFZkHmRi",
        "outputId": "e32e5bdf-dc75-46dc-946c-4bafd332f4a4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.2 Motif-level Similarity (Cosine Similarity)\n",
        "\n",
        "- To quantify similarity between motifs, cosine similarity is computed between their feature vectors.\n",
        "Cosine similarity measures the angular similarity between vectors, focusing on distributional shape rather than absolute magnitude.\n",
        "\n",
        "- This is well suited for percentage-based symbolic features and provides an interpretable measure of stylistic closeness between motifs.\n"
      ],
      "metadata": {
        "id": "JcVbdMAuI55V"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "#remove à¹„à¸—à¸¢à¹€à¸”à¸´à¸¡ as of now data not complete\n",
        "\n",
        "# Remove motifs with insufficient data\n",
        "motif_vectors = {\n",
        "    m: v for m, v in motif_vectors.items()\n",
        "    if m not in {\"à¹„à¸—à¸¢à¹€à¸”à¸´à¸¡\", \"à¸žà¸¡à¹ˆà¸²\"}\n",
        "}"
      ],
      "metadata": {
        "id": "Z5urpA-KNe6O"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "motifs = list(motif_vectors.keys())\n",
        "X = np.vstack([motif_vectors[m] for m in motifs])\n",
        "\n",
        "X.shape   # (num_motifs, 10)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xYchu--ZI7C6",
        "outputId": "c83f8b39-ed81-474e-f06d-c36c04702209"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "sim_matrix = cosine_similarity(X)\n",
        "\n",
        "df_similarity = pd.DataFrame(\n",
        "    sim_matrix,\n",
        "    index=motifs,\n",
        "    columns=motifs\n",
        ")\n",
        "\n",
        "df_similarity"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 175
        },
        "id": "P5zfZzteJE9W",
        "outputId": "0ebd0c60-66f1-4b4e-d102-0c283fbe84ae"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "import numpy as np\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.imshow(df_similarity.values, cmap=\"viridis\", vmin=0.9, vmax=1.0)\n",
        "plt.colorbar(label=\"Cosine Similarity\")\n",
        "\n",
        "plt.xticks(range(len(df_similarity.columns)), df_similarity.columns, rotation=45)\n",
        "plt.yticks(range(len(df_similarity.index)), df_similarity.index)\n",
        "\n",
        "plt.title(\"Motif-level Cosine Similarity\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "37MS0QbTJ1A4",
        "outputId": "1cb06c86-4128-4104-9095-899c8adb5a7f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "At this stage, each motif is represented by a single 10-dimensional vector obtained by aggregating symbolic statistics across all songs of that motif.\n"
      ],
      "metadata": {
        "id": "MohqzbS_KcnU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Feature vector V2 (13D)\n",
        "\t1.\tDirectional interval stats (up / down / same)  â†’ +3D\n"
      ],
      "metadata": {
        "id": "CjGTyxBiYbOP"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# Numeric ordering (for intervals / direction)\n",
        "PITCH_TO_INT = {\n",
        "    \"à¸”\": 0, \"à¸£\": 1, \"à¸¡\": 2, \"à¸Ÿ\": 3, \"à¸‹\": 4, \"à¸¥\": 5, \"à¸—\": 6,\n",
        "}\n",
        "\n",
        "# Just for display / plotting\n",
        "PITCH_LIST = [\"à¸”\", \"à¸£\", \"à¸¡\", \"à¸Ÿ\", \"à¸‹\", \"à¸¥\", \"à¸—\"]"
      ],
      "metadata": {
        "id": "qkS9CtgFa8lW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def directional_interval_stats(symbols):\n",
        "    \"\"\"\n",
        "    Compute directional interval percentages: up / down / same.\n",
        "    \"\"\"\n",
        "    up = down = same = 0\n",
        "\n",
        "    for a, b in zip(symbols, symbols[1:]):\n",
        "        if a not in PITCH_ORDER or b not in PITCH_ORDER:\n",
        "            continue\n",
        "\n",
        "        ia = PITCH_TO_INT[a]\n",
        "        ib = PITCH_TO_INT[b]\n",
        "\n",
        "        if ib > ia:\n",
        "            up += 1\n",
        "        elif ib < ia:\n",
        "            down += 1\n",
        "        else:\n",
        "            same += 1\n",
        "\n",
        "    total = up + down + same\n",
        "    if total == 0:\n",
        "        return [0.0, 0.0, 0.0]\n",
        "\n",
        "    return [\n",
        "        up / total * 100,\n",
        "        down / total * 100,\n",
        "        same / total * 100\n",
        "    ]\n",
        "\n",
        "def motif_directional_vector(songs, motif):\n",
        "    all_symbols = []\n",
        "    for s in songs:\n",
        "        if s[\"motif\"] == motif:\n",
        "            all_symbols.extend(s[\"symbol_sequence\"])\n",
        "\n",
        "    return directional_interval_stats(all_symbols)\n"
      ],
      "metadata": {
        "id": "roc12TtCYXs2"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "motif_vectors_v2 = {}\n",
        "\n",
        "for motif, base_vec in motif_vectors.items():\n",
        "    dir_vec = motif_directional_vector(songs, motif)\n",
        "    motif_vectors_v2[motif] = np.concatenate([base_vec, dir_vec])"
      ],
      "metadata": {
        "id": "uWdxf0DxYnCz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "motif_vectors_v2[\"à¸¥à¸²à¸§\"].shape\n",
        "# should now be (13,)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XYW01lEIYrlc",
        "outputId": "c826a76f-32cc-4194-90d4-6e6e0d704e68"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4.x fragment-to-motif demo\n"
      ],
      "metadata": {
        "id": "USA_HOFXK3QI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fragment_symbols(song, n_symbols=16):\n",
        "    \"\"\"\n",
        "    Extract a short fragment (approx. 2 bars) from a song.\n",
        "    \"\"\"\n",
        "    return song[\"symbol_sequence\"][:n_symbols]\n",
        "\n",
        "\n",
        "def pitch_vector_from_symbols(symbols):\n",
        "    from collections import Counter\n",
        "\n",
        "    counter = Counter(symbols)\n",
        "    total = sum(counter.values())\n",
        "\n",
        "    return [\n",
        "        counter.get(n, 0) / total * 100 if total else 0\n",
        "        for n in PITCH_ORDER\n",
        "    ]\n",
        "\n",
        "def interval_vector_from_symbols(symbols):\n",
        "    intervals = []\n",
        "    for a, b in zip(symbols, symbols[1:]):\n",
        "        if a in PITCH_ORDER and b in PITCH_ORDER:\n",
        "            intervals.append(PITCH_ORDER.index(b) - PITCH_ORDER.index(a))\n",
        "\n",
        "    bins = {\"stepwise\": 0, \"medium\": 0, \"large\": 0}\n",
        "\n",
        "    for iv in intervals:\n",
        "        a = abs(iv)\n",
        "        if a <= 1:\n",
        "            bins[\"stepwise\"] += 1\n",
        "        elif a <= 3:\n",
        "            bins[\"medium\"] += 1\n",
        "        else:\n",
        "            bins[\"large\"] += 1\n",
        "\n",
        "    total = sum(bins.values())\n",
        "    return [\n",
        "        bins[\"stepwise\"] / total * 100 if total else 0,\n",
        "        bins[\"medium\"] / total * 100 if total else 0,\n",
        "        bins[\"large\"] / total * 100 if total else 0,\n",
        "    ]\n",
        "\n",
        "import numpy as np\n",
        "\n",
        "def fragment_vector(symbols):\n",
        "    return np.array(\n",
        "        pitch_vector_from_symbols(symbols)\n",
        "        + interval_vector_from_symbols(symbols)\n",
        "    )"
      ],
      "metadata": {
        "id": "DryimyHVKc7B"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def fragment_vector_v2(symbols):\n",
        "    # v1 features\n",
        "    pitch_vec = pitch_vector_from_symbols(symbols)\n",
        "    interval_vec = interval_vector_from_symbols(symbols)\n",
        "\n",
        "    # new v2 feature\n",
        "    dir_vec = directional_interval_stats(symbols)\n",
        "\n",
        "    return np.concatenate([pitch_vec, interval_vec, dir_vec])  # 13D"
      ],
      "metadata": {
        "id": "IvOSQGO8b5T6"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Play around here (only v1 and v2?)\n"
      ],
      "metadata": {
        "id": "ESOOJvG0N95S"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "raw_frag = [ \"--à¸”à¹à¸¥\", \"à¸”à¹à¸¥à¸£à¹à¸”à¹\", \"--à¸Ÿà¸£\", \"à¸Ÿà¸£à¸‹à¸Ÿ\", \"--à¸”à¹à¸¥\", \"--à¸£à¹à¸”à¹\", \"à¸Ÿà¸£à¸‹à¸Ÿ\", \"à¸¥à¸‹à¸”à¹à¸¥\" ] #khmer à¹€à¸‚à¸¡à¸£\n",
        "frag = extract_symbols(raw_frag, strip_octave=True)"
      ],
      "metadata": {
        "id": "fyd_87pKMTn5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_frag = [ \"à¸”à¹à¸£à¹à¸”à¹à¸¥\", \"à¸”à¹à¸‹à¸¥à¸”à¹\", \"à¸”à¹à¸£à¹à¸”à¹à¸¥\", \"à¸”à¹à¸¥à¸‹à¸Ÿ\", \"----\", \"à¸”à¸£à¸Ÿà¸‹\", \"à¸¥à¸Ÿà¸¥à¸‹\", \"-à¸Ÿ-à¸£\" ] #khmer à¹€à¸‚à¸¡à¸£\n",
        "frag = extract_symbols(raw_frag, strip_octave=True)\n"
      ],
      "metadata": {
        "id": "6RK6wQF4dGdz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_frag = [ \"----\", \"----\", \"-à¸‹-à¸¥\", \"-à¸—-à¸”à¹\", \"---à¸—\", \"--à¸”à¹à¸£à¹\", \"à¸¡à¹à¸£à¹à¸”à¹à¸—\", \"à¸”à¹à¸£à¹-à¸”à¹\" ] #à¹à¸‚à¸\n",
        "frag = extract_symbols(raw_frag, strip_octave=True)"
      ],
      "metadata": {
        "id": "QUqcKfOeOO3u"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_frag = [ \"----\", \"----\", \"--à¸‹à¸¥\", \"à¸”à¹à¸¡à¸£à¸”\", \"à¸£à¸¡-à¸‹\", \"-à¸¥--\", \"à¸”à¹à¸¥à¸‹à¸¡\", \"à¸‹à¸¥-à¸”à¹\",\"à¸£à¹à¸¡à¹à¸£à¹à¸”à¹\" ] #à¸¥à¸²à¸§\n",
        "frag = extract_symbols(raw_frag, strip_octave=True)"
      ],
      "metadata": {
        "id": "EA1W0XWLPG2F"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_frag = [\n",
        "          \"----\",\n",
        "          \"à¸£à¸¡à¸‹à¸¥\",\n",
        "          \"à¸‹à¸¥à¸”à¹à¸¥\",\n",
        "          \"-à¸‹à¸‹à¸‹\",\n",
        "          \"-à¸”à¸£à¸¡\",\n",
        "          \"-à¸‹-à¸¥\",\n",
        "          \"-à¸”à¹-à¸¡à¹\",\n",
        "          \"-à¸£à¹à¸¡à¹à¸‹à¹\"\n",
        "        ] #à¸¥à¸²à¸§\n",
        "frag = extract_symbols(raw_frag, strip_octave=True)"
      ],
      "metadata": {
        "id": "zSR6LML6Pzgr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_frag =[\n",
        "          \"à¸”à¹à¸¥à¸‹à¸¡\",\n",
        "          \"-à¸£-à¸”\",\n",
        "          \"--à¸¡à¸£\",\n",
        "          \"à¸”à¸£-à¸¡\",\n",
        "          \"à¸£à¸”-à¸£\",\n",
        "          \"-à¸¡-à¸‹\",\n",
        "          \"à¸¥à¸‹à¸”à¹à¸¥\",\n",
        "          \"à¸‹à¸¡-à¸£\"\n",
        "        ] #à¸¥à¸²à¸§\n",
        "\n",
        "frag = extract_symbols(raw_frag, strip_octave=True)"
      ],
      "metadata": {
        "id": "mY1vrwN1cq-1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "frag_vec = fragment_vector(frag)\n",
        "\n",
        "scores = {}\n",
        "for motif, vec in motif_vectors.items():\n",
        "    scores[motif] = cosine_similarity(\n",
        "        frag_vec.reshape(1, -1),\n",
        "        vec.reshape(1, -1)\n",
        "    )[0, 0]\n",
        "\n",
        "sorted(scores.items(), key=lambda x: x[1], reverse=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6A1X7mKVMNT0",
        "outputId": "c19612c9-69f4-4fe4-f027-3be1a76d3cd4"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "frag_vec = fragment_vector_v2(frag)\n",
        "\n",
        "scores = {}\n",
        "for motif, vec in motif_vectors_v2.items():\n",
        "    scores[motif] = cosine_similarity(\n",
        "        frag_vec.reshape(1, -1),\n",
        "        vec.reshape(1, -1)\n",
        "    )[0, 0]\n",
        "\n",
        "sorted(scores.items(), key=lambda x: x[1], reverse=True)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Q8kQLAiTbjRA",
        "outputId": "30510766-d3cc-4ff8-c034-309a985a09dc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## 4. Feature vector building for Motifs cleaned\n",
        "\n",
        "Each motif is represented by a fixed-dimensional feature vector ð’› that summarizes its symbolic melodic characteristics.\n",
        "\n",
        "- The first part of ð’› encodes the octave-agnostic pitch distribution (à¸”, à¸£, à¸¡, à¸Ÿ, à¸‹, à¸¥, à¸—), capturing melodic vocabulary preferences.\n",
        "- The second part of ð’› encodes interval magnitude statistics (stepwise, medium, large), capturing characteristic melodic motion patterns.\n",
        "\n",
        "This compact representation enables direct quantitative comparison between motifs using standard similarity measures.\n",
        "\n",
        "\n",
        "\t1.\tBase 7D (notes) + Directional interval stats (up / down / same)  â†’ +3D\n",
        "\t2.\tInterval entropy â†’ +1D\n",
        "\t3.\tPitch-class entropy â†’ +1D\n",
        "\t4.\tTop-K pitch bigram frequencies â†’ +K D (weâ€™ll keep K small, e.g. 5â€“10)\n"
      ],
      "metadata": {
        "id": "qmaR-MP3GEXh"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Helpers for Vectors\n"
      ],
      "metadata": {
        "id": "Xwz8e4iqGwyV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Pitch definitions =====\n",
        "PITCH_ORDER = [\"à¸”\", \"à¸£\", \"à¸¡\", \"à¸Ÿ\", \"à¸‹\", \"à¸¥\", \"à¸—\"]\n",
        "\n",
        "PITCH_TO_INT = {\n",
        "    \"à¸”\": 0, \"à¸£\": 1, \"à¸¡\": 2, \"à¸Ÿ\": 3, \"à¸‹\": 4, \"à¸¥\": 5, \"à¸—\": 6,\n",
        "}\n",
        "\n",
        "# ===== Symbol helpers =====\n",
        "from collections import Counter\n",
        "import numpy as np\n",
        "\n",
        "\n",
        "# Pitch statistics\n",
        "def pitch_vector_from_symbols(symbols):\n",
        "    counter = Counter(symbols)\n",
        "    total = sum(counter.values())\n",
        "\n",
        "    return [\n",
        "        counter.get(n, 0) / total * 100 if total else 0\n",
        "        for n in PITCH_ORDER\n",
        "    ]\n",
        "\n",
        "#Interval statistics (magnitude)\n",
        "def interval_vector_from_symbols(symbols):\n",
        "    intervals = []\n",
        "\n",
        "    for a, b in zip(symbols, symbols[1:]):\n",
        "        if a in PITCH_TO_INT and b in PITCH_TO_INT:\n",
        "            intervals.append(PITCH_TO_INT[b] - PITCH_TO_INT[a])\n",
        "\n",
        "    bins = {\"stepwise\": 0, \"medium\": 0, \"large\": 0}\n",
        "\n",
        "    for iv in intervals:\n",
        "        a = abs(iv)\n",
        "        if a <= 1:\n",
        "            bins[\"stepwise\"] += 1\n",
        "        elif a <= 3:\n",
        "            bins[\"medium\"] += 1\n",
        "        else:\n",
        "            bins[\"large\"] += 1\n",
        "\n",
        "    total = sum(bins.values())\n",
        "    return [\n",
        "        bins[\"stepwise\"] / total * 100 if total else 0,\n",
        "        bins[\"medium\"] / total * 100 if total else 0,\n",
        "        bins[\"large\"] / total * 100 if total else 0,\n",
        "    ]\n",
        "\n",
        "#for V2\n",
        "def directional_interval_stats(symbols):\n",
        "    up = down = same = 0\n",
        "\n",
        "    for a, b in zip(symbols, symbols[1:]):\n",
        "        if a not in PITCH_TO_INT or b not in PITCH_TO_INT:\n",
        "            continue\n",
        "\n",
        "        ia = PITCH_TO_INT[a]\n",
        "        ib = PITCH_TO_INT[b]\n",
        "\n",
        "        if ib > ia:\n",
        "            up += 1\n",
        "        elif ib < ia:\n",
        "            down += 1\n",
        "        else:\n",
        "            same += 1\n",
        "\n",
        "    total = up + down + same\n",
        "    if total == 0:\n",
        "        return [0.0, 0.0, 0.0]\n",
        "\n",
        "    return [\n",
        "        up / total * 100,\n",
        "        down / total * 100,\n",
        "        same / total * 100,\n",
        "    ]\n",
        "\n",
        "\n",
        "#for V3\n",
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "def interval_entropy(symbols):\n",
        "    \"\"\"\n",
        "    Shannon entropy of signed pitch intervals.\n",
        "    \"\"\"\n",
        "    intervals = []\n",
        "    for a, b in zip(symbols, symbols[1:]):\n",
        "        if a in PITCH_TO_INT and b in PITCH_TO_INT:\n",
        "            intervals.append(PITCH_TO_INT[b] - PITCH_TO_INT[a])\n",
        "\n",
        "    if not intervals:\n",
        "        return 0.0\n",
        "\n",
        "    counter = Counter(intervals)\n",
        "    total = sum(counter.values())\n",
        "\n",
        "    entropy = 0.0\n",
        "    for cnt in counter.values():\n",
        "        p = cnt / total\n",
        "        entropy -= p * math.log2(p)\n",
        "\n",
        "    return entropy\n",
        "\n",
        "\n",
        "# for V4\n",
        "import math\n",
        "from collections import Counter\n",
        "\n",
        "def pitch_class_entropy(symbols):\n",
        "    \"\"\"\n",
        "    Shannon entropy of pitch-class usage (octave-agnostic).\n",
        "    \"\"\"\n",
        "    pitches = [s for s in symbols if s in PITCH_ORDER]\n",
        "    if not pitches:\n",
        "        return 0.0\n",
        "\n",
        "    counter = Counter(pitches)\n",
        "    total = sum(counter.values())\n",
        "\n",
        "    entropy = 0.0\n",
        "    for cnt in counter.values():\n",
        "        p = cnt / total\n",
        "        entropy -= p * math.log2(p)\n",
        "\n",
        "    return entropy\n",
        "\n",
        "#for V5\n",
        "from collections import Counter\n",
        "\n",
        "def extract_pitch_bigrams(symbols):\n",
        "    \"\"\"\n",
        "    Extract pitch bigrams (order-sensitive, octave-agnostic).\n",
        "    \"\"\"\n",
        "    pitches = [s for s in symbols if s in PITCH_ORDER]\n",
        "    return list(zip(pitches, pitches[1:]))\n",
        "\n",
        "def get_top_k_bigrams(songs, motifs, K=8):\n",
        "    counter = Counter()\n",
        "\n",
        "    for s in songs:\n",
        "        if s[\"motif\"] in motifs:\n",
        "            bigrams = extract_pitch_bigrams(s[\"symbol_sequence\"])\n",
        "            counter.update(bigrams)\n",
        "\n",
        "    return [bg for bg, _ in counter.most_common(K)]"
      ],
      "metadata": {
        "id": "GSOkvMxDGMsa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### V1 (10D) BASE\n",
        "  - **pitch** : dimensions 1â€“7 â†’ what notes are used\n",
        "  - **interval** : dimensions 8â€“10 â†’ how melodies move\n"
      ],
      "metadata": {
        "id": "0GE1jdfNGzw8"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def motif_vector_v1(songs, motif):\n",
        "    all_symbols = []\n",
        "    for s in songs:\n",
        "        if s[\"motif\"] == motif:\n",
        "            all_symbols.extend(s[\"symbol_sequence\"])\n",
        "\n",
        "    pitch_vec = pitch_vector_from_symbols(all_symbols)          #7D\n",
        "    interval_vec = interval_vector_from_symbols(all_symbols)    #3D\n",
        "\n",
        "    return np.array(pitch_vec + interval_vec)"
      ],
      "metadata": {
        "id": "37lux7AdHCPi"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "motif_vectors_v1 = {\n",
        "    motif: motif_vector_v1(songs, motif)\n",
        "    for motif in {\"à¸¥à¸²à¸§\", \"à¹€à¸‚à¸¡à¸£\", \"à¹à¸‚à¸\", \"à¸ˆà¸µà¸™\", \"à¸žà¸¡à¹ˆà¸²\"}  # filtered motifs\n",
        "}"
      ],
      "metadata": {
        "id": "guOVkhGbHKX1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### V2 (13D)\n",
        "\n",
        "- 7D **Pitch** (1â€“7): pitch-class usage (à¸” à¸£ à¸¡ à¸Ÿ à¸‹ à¸¥ à¸—)\n",
        "- 3D **Interval** (8â€“10): stepwise / medium / large motion\n",
        "- 3D **Direction** (11â€“13): up / down / same movement\n"
      ],
      "metadata": {
        "id": "1BlHlKm6IJhf"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def motif_vector_v2(songs, motif):\n",
        "    base = motif_vector_v1(songs, motif)\n",
        "    dir_vec = directional_interval_stats(   # +3D\n",
        "        [sym for s in songs if s[\"motif\"] == motif for sym in s[\"symbol_sequence\"]]\n",
        "    )\n",
        "    return np.concatenate([base, dir_vec])"
      ],
      "metadata": {
        "id": "kN6hmKqiILZH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "motif_vectors_v2 = {\n",
        "    motif: motif_vector_v2(songs, motif)\n",
        "    for motif in motif_vectors_v1\n",
        "}"
      ],
      "metadata": {
        "id": "ui2cnU78IwJ0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### V3 (14D)\n",
        "\n",
        "- **Pitch** (1â€“7): pitch-class usage  \n",
        "- **Interval** (8â€“10): stepwise / medium / large motion  \n",
        "- **Direction** (11â€“13): up / down / same movement  \n",
        "- **Interval entropy** (14): variability of interval usage\n"
      ],
      "metadata": {
        "id": "UR6Ey7KyJ_Xl"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def motif_vector_v3(songs, motif):\n",
        "    # base V2\n",
        "    base = motif_vector_v2(songs, motif)\n",
        "\n",
        "    # interval entropy\n",
        "    all_symbols = [\n",
        "        sym\n",
        "        for s in songs if s[\"motif\"] == motif\n",
        "        for sym in s[\"symbol_sequence\"]\n",
        "    ]\n",
        "    ent = interval_entropy(all_symbols)\n",
        "\n",
        "    return np.concatenate([base, [ent]])\n"
      ],
      "metadata": {
        "id": "ZrVBlOLLKRu0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "motif_vectors_v3 = {\n",
        "    motif: motif_vector_v3(songs, motif)\n",
        "    for motif in motif_vectors_v2\n",
        "}"
      ],
      "metadata": {
        "id": "1LI3xDUdKhXP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### V4 (15D)\n",
        "\n",
        "- **Pitch** (1â€“7): pitch-class usage  \n",
        "- **Interval** (8â€“10): stepwise / medium / large motion  \n",
        "- **Direction** (11â€“13): up / down / same movement  \n",
        "- **Interval entropy** (14): variability of interval usage  \n",
        "- **Pitch-class entropy** (15): concentration vs spread of pitch usage\n"
      ],
      "metadata": {
        "id": "gADDjGWlTK1v"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def motif_vector_v4(songs, motif):\n",
        "    base = motif_vector_v3(songs, motif)\n",
        "\n",
        "    all_symbols = [\n",
        "        sym\n",
        "        for s in songs if s[\"motif\"] == motif\n",
        "        for sym in s[\"symbol_sequence\"]\n",
        "    ]\n",
        "    p_ent = pitch_class_entropy(all_symbols)\n",
        "\n",
        "    return np.concatenate([base, [p_ent]])"
      ],
      "metadata": {
        "id": "HnbUvdFgTcY5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "motif_vectors_v4 = {\n",
        "    motif: motif_vector_v4(songs, motif)\n",
        "    for motif in motif_vectors_v3\n",
        "}"
      ],
      "metadata": {
        "id": "OGqKnlCcTd-f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### V5 (15 + K D)\n",
        "\n",
        "- **Pitch** (1â€“7): pitch-class usage  \n",
        "- **Interval** (8â€“10): stepwise / medium / large motion  \n",
        "- **Direction** (11â€“13): up / down / same movement  \n",
        "- **Interval entropy** (14): variability of interval usage  \n",
        "- **Pitch-class entropy** (15): concentration of pitch usage  \n",
        "- **Top-K pitch bigrams** (16â€“15+K): characteristic pitch transitions\n"
      ],
      "metadata": {
        "id": "lEGHRF31VCDH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MOTIFS_USED = list(motif_vectors_v4.keys())\n",
        "TOP_K = 25\n",
        "\n",
        "TOP_K_BIGRAMS = get_top_k_bigrams(songs, MOTIFS_USED, K=TOP_K)\n",
        "TOP_K_BIGRAMS"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "iLy9Jh2WVdNN",
        "outputId": "5bc8ebe0-c1aa-4af3-be02-a250303bf4fa"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def bigram_vector_from_symbols(symbols, top_k_bigrams):\n",
        "    bigrams = extract_pitch_bigrams(symbols)\n",
        "    counter = Counter(bigrams)\n",
        "    total = sum(counter.values())\n",
        "\n",
        "    return [\n",
        "        counter.get(bg, 0) / total * 100 if total else 0\n",
        "        for bg in top_k_bigrams\n",
        "    ]"
      ],
      "metadata": {
        "id": "bM-Vfzn3VxRR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def motif_vector_v5(songs, motif, top_k_bigrams):\n",
        "    base = motif_vector_v4(songs, motif)\n",
        "\n",
        "    all_symbols = [\n",
        "        sym\n",
        "        for s in songs if s[\"motif\"] == motif\n",
        "        for sym in s[\"symbol_sequence\"]\n",
        "    ]\n",
        "\n",
        "    bg_vec = bigram_vector_from_symbols(all_symbols, top_k_bigrams)\n",
        "\n",
        "    return np.concatenate([base, bg_vec])"
      ],
      "metadata": {
        "id": "MzBWZ6enWOCI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "motif_vectors_v5 = {\n",
        "    motif: motif_vector_v5(songs, motif, TOP_K_BIGRAMS)\n",
        "    for motif in motif_vectors_v4\n",
        "}"
      ],
      "metadata": {
        "id": "XCDhhgDtWQMw"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cosine Sim V1 to V5 motifs to motifs\n"
      ],
      "metadata": {
        "id": "cRFfKZIXxZNk"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ===== Motif-level cosine similarity (V2) =====\n",
        "\n",
        "motifs = list(motif_vectors_v2.keys())\n",
        "X = np.vstack([motif_vectors_v2[m] for m in motifs])\n",
        "\n",
        "sim_matrix = cosine_similarity(X)\n",
        "\n",
        "df_similarity_v2 = pd.DataFrame(\n",
        "    sim_matrix,\n",
        "    index=motifs,\n",
        "    columns=motifs\n",
        ")\n",
        "\n",
        "df_similarity_v2"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "HBljbE6ytRF8",
        "outputId": "c1220bba-9dc1-410f-be4e-06a67fe0f446"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.imshow(df_similarity_v2.values, cmap=\"viridis\")\n",
        "plt.colorbar(label=\"Cosine Similarity\")\n",
        "\n",
        "plt.xticks(range(len(motifs)), motifs, rotation=45)\n",
        "plt.yticks(range(len(motifs)), motifs)\n",
        "\n",
        "plt.title(\"Motif-level Cosine Similarity (V2)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 513
        },
        "id": "6IeaVA9VxJxn",
        "outputId": "42acfe08-feb2-447c-ae40-05cf38d0b7b5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "# ===== Motif-level cosine similarity (V2) =====\n",
        "\n",
        "motifs = list(motif_vectors_v5.keys())\n",
        "X = np.vstack([motif_vectors_v5[m] for m in motifs])\n",
        "\n",
        "sim_matrix = cosine_similarity(X)\n",
        "\n",
        "df_similarity_v5 = pd.DataFrame(\n",
        "    sim_matrix,\n",
        "    index=motifs,\n",
        "    columns=motifs\n",
        ")\n",
        "\n",
        "df_similarity_v5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "pE3ESwtnxeZY",
        "outputId": "bd4f18f7-47d2-4863-d087-d4a267c8c879"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "plt.figure(figsize=(6, 5))\n",
        "plt.imshow(df_similarity_v5.values, cmap=\"viridis\")\n",
        "plt.colorbar(label=\"Cosine Similarity\")\n",
        "\n",
        "plt.xticks(range(len(motifs)), motifs, rotation=45)\n",
        "plt.yticks(range(len(motifs)), motifs)\n",
        "\n",
        "plt.title(\"Motif-level Cosine Similarity (V5)\")\n",
        "plt.tight_layout()\n",
        "plt.show()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 519
        },
        "id": "aywUxBdJxioM",
        "outputId": "c5ab98e5-39d8-4e95-f25c-7c33c88cf282"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Fragment Vectorization (for testing)\n"
      ],
      "metadata": {
        "id": "T8-SaHIKI3Pq"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def get_fragment_symbols(song, n_symbols=16):\n",
        "    return song[\"symbol_sequence\"][:n_symbols]\n",
        "\n",
        "def fragment_vector_v1(symbols):\n",
        "    return np.array(\n",
        "        pitch_vector_from_symbols(symbols)\n",
        "        + interval_vector_from_symbols(symbols)\n",
        "    )\n",
        "\n",
        "def fragment_vector_v2(symbols):\n",
        "    return np.concatenate([\n",
        "        fragment_vector_v1(symbols),\n",
        "        directional_interval_stats(symbols)\n",
        "    ])\n",
        "\n",
        "def fragment_vector_v3(symbols):\n",
        "    base = fragment_vector_v2(symbols)\n",
        "    ent = interval_entropy(symbols)\n",
        "    return np.concatenate([base, [ent]])\n",
        "\n",
        "def fragment_vector_v4(symbols):\n",
        "    base = fragment_vector_v3(symbols)\n",
        "    p_ent = pitch_class_entropy(symbols)\n",
        "    return np.concatenate([base, [p_ent]])\n",
        "\n",
        "def fragment_vector_v5(symbols, top_k_bigrams):\n",
        "    base = fragment_vector_v4(symbols)\n",
        "    bg_vec = bigram_vector_from_symbols(symbols, top_k_bigrams)\n",
        "    return np.concatenate([base, bg_vec])"
      ],
      "metadata": {
        "id": "b6Mn3zp6I6eO"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Cosine Similarity demo with fragment\n",
        "\n",
        "\n",
        "\n",
        "\n"
      ],
      "metadata": {
        "id": "djxfRydYJTqt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "\n",
        "def rank_fragment(fragment_vec, motif_vectors):\n",
        "    return sorted(\n",
        "        {\n",
        "            motif: cosine_similarity(\n",
        "                fragment_vec.reshape(1, -1),\n",
        "                vec.reshape(1, -1)\n",
        "            )[0, 0]\n",
        "            for motif, vec in motif_vectors.items()\n",
        "        }.items(),\n",
        "        key=lambda x: x[1],\n",
        "        reverse=True\n",
        "    )"
      ],
      "metadata": {
        "id": "caZhf4vjJWbJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_frag = [ \"--à¸”à¹à¸¥\", \"à¸”à¹à¸¥à¸£à¹à¸”à¹\", \"--à¸Ÿà¸£\", \"à¸Ÿà¸£à¸‹à¸Ÿ\", \"--à¸”à¹à¸¥\", \"--à¸£à¹à¸”à¹\", \"à¸Ÿà¸£à¸‹à¸Ÿ\", \"à¸¥à¸‹à¸”à¹à¸¥\" ] #khmer à¹€à¸‚à¸¡à¸£\n",
        "frag = extract_symbols(raw_frag, strip_octave=True)"
      ],
      "metadata": {
        "id": "DYtSJR_FJd5I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_frag = [ \"à¸”à¹à¸£à¹à¸”à¹à¸¥\", \"à¸”à¹à¸‹à¸¥à¸”à¹\", \"à¸”à¹à¸£à¹à¸”à¹à¸¥\", \"à¸”à¹à¸¥à¸‹à¸Ÿ\", \"----\", \"à¸”à¸£à¸Ÿà¸‹\", \"à¸¥à¸Ÿà¸¥à¸‹\", \"-à¸Ÿ-à¸£\" ] #khmer à¹€à¸‚à¸¡à¸£\n",
        "frag = extract_symbols(raw_frag, strip_octave=True)\n"
      ],
      "metadata": {
        "id": "IEN46DOdJgRv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_frag = [ \"----\", \"----\", \"-à¸‹-à¸¥\", \"-à¸—-à¸”à¹\", \"---à¸—\", \"--à¸”à¹à¸£à¹\", \"à¸¡à¹à¸£à¹à¸”à¹à¸—\", \"à¸”à¹à¸£à¹-à¸”à¹\" ] #à¹à¸‚à¸\n",
        "frag = extract_symbols(raw_frag, strip_octave=True)"
      ],
      "metadata": {
        "id": "gZ66beYEJiZt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_frag = [ \"----\", \"----\", \"--à¸‹à¸¥\", \"à¸”à¹à¸¡à¸£à¸”\", \"à¸£à¸¡-à¸‹\", \"-à¸¥--\", \"à¸”à¹à¸¥à¸‹à¸¡\", \"à¸‹à¸¥-à¸”à¹\",\"à¸£à¹à¸¡à¹à¸£à¹à¸”à¹\" ] #à¸¥à¸²à¸§ correct\n",
        "frag = extract_symbols(raw_frag, strip_octave=True)"
      ],
      "metadata": {
        "id": "32UomqaZJkVG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_frag = [\n",
        "          \"----\",\n",
        "          \"à¸£à¸¡à¸‹à¸¥\",\n",
        "          \"à¸‹à¸¥à¸”à¹à¸¥\",\n",
        "          \"-à¸‹à¸‹à¸‹\",\n",
        "          \"-à¸”à¸£à¸¡\",\n",
        "          \"-à¸‹-à¸¥\",\n",
        "          \"-à¸”à¹-à¸¡à¹\",\n",
        "          \"-à¸£à¹à¸¡à¹à¸‹à¹\"\n",
        "        ] #à¸¥à¸²à¸§  correct\n",
        "frag = extract_symbols(raw_frag, strip_octave=True)"
      ],
      "metadata": {
        "id": "Y961MMzdJoMV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_frag =[\n",
        "          \"à¸”à¹à¸¥à¸‹à¸¡\",\n",
        "          \"-à¸£-à¸”\",\n",
        "          \"--à¸¡à¸£\",\n",
        "          \"à¸”à¸£-à¸¡\",\n",
        "          \"à¸£à¸”-à¸£\",\n",
        "          \"-à¸¡-à¸‹\",\n",
        "          \"à¸¥à¸‹à¸”à¹à¸¥\",\n",
        "          \"à¸‹à¸¡-à¸£\"\n",
        "        ] #à¸¥à¸²à¸§ expected wrong\n",
        "\n",
        "frag = extract_symbols(raw_frag, strip_octave=True)"
      ],
      "metadata": {
        "id": "xofyxmu2Jn_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_frag = [\n",
        "          \"---à¸Ÿ\",\n",
        "          \"--à¸¥à¸”à¹\",\n",
        "          \"-à¸”à¹-à¸£à¹\",\n",
        "          \"à¸”à¹à¸”à¹à¸”à¹à¸”à¹\",\n",
        "          \"-à¸Ÿà¹-à¸¥\",\n",
        "          \"à¸”à¹à¸”à¹à¸”à¹à¸”à¹\",\n",
        "          \"-à¸¥-à¸£à¹\",\n",
        "          \"à¸”à¹à¸”à¹à¸”à¹à¸”à¹\"\n",
        "        ]  #à¸¥à¸²à¸§ expected wrong\n",
        "\n",
        "frag = extract_symbols(raw_frag, strip_octave=True)"
      ],
      "metadata": {
        "id": "GXzjgbneLDtb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_frag = [\n",
        "          \"-à¸¡à¹-à¸£à¹\",\n",
        "          \"-à¸”à¹à¸£à¹à¸¡à¹\",\n",
        "          \"--à¸”à¹à¸£à¹\",\n",
        "          \"à¸¡à¹à¸£à¹à¸”à¹à¸¥\",\n",
        "          \"--à¸”à¹à¸¥\",\n",
        "          \"à¸‹à¸¡à¸‹à¸¥\",\n",
        "          \"-à¸”à¹à¸£à¹à¸¡à¹\",\n",
        "          \"-à¸£à¹-à¸”à¹\"\n",
        "        ]\n",
        "frag = extract_symbols(raw_frag, strip_octave=True)"
      ],
      "metadata": {
        "id": "ki9wQrkyMEe7"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_frag = [\"----\",\"à¸¡à¸”à¸£à¸¡\",\"à¸£à¸¡à¸Ÿà¸‹\",\"à¸Ÿà¸‹à¸—à¸¥\",\"-à¸¥à¸¥-\",\"à¸‹à¸Ÿà¸¡à¸Ÿ\",\"-à¸Ÿà¸Ÿ-\",\"à¸¡à¸£à¸”à¸£\"]\n",
        "frag = extract_symbols(raw_frag, strip_octave=True)"
      ],
      "metadata": {
        "id": "YWIGuh_Zatcq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_frag = [ \"-à¸£à¸‹à¸¥\", \"à¸—à¸”à¹à¸£à¹\", \"--à¸”à¹à¸¡à¹\", \"à¸£à¹à¸”à¹à¸—à¸¥\", \"à¸—à¸¥à¸‹à¸”à¹\", \"-à¸—-à¸¥\", \"à¸—à¸¥à¸‹à¸¥\", \"à¸‹à¸Ÿà¸¡à¸Ÿ\" ] #khaek\n",
        "frag = extract_symbols(raw_frag, strip_octave=True)"
      ],
      "metadata": {
        "id": "3gwWpZlKMf-z"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "raw_frag = [ \"----\", \"-à¸¡à¹à¸£à¹à¸”à¹\", \"--à¸¥à¸‹\", \"à¸¡à¸‹à¸¥à¸”à¹\", \"-à¸‹à¸¥à¸‹\", \"à¸¥à¸”à¹-à¸¥\", \"à¸”à¹à¸¥à¸‹à¸¡\", \"-à¸£à¸¡à¸‹\" ]\n",
        "frag = extract_symbols(raw_frag, strip_octave=True)"
      ],
      "metadata": {
        "id": "_4OqcRwzj6BV"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rank_fragment(fragment_vector_v1(frag), motif_vectors_v1)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Nd3xTpmzJuo7",
        "outputId": "d6ec6bb7-8f14-49ae-bff5-4e5cb85d7f0e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rank_fragment(fragment_vector_v2(frag), motif_vectors_v2)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "58nzVal4JwK4",
        "outputId": "b4186967-defe-41e4-c9a0-bc0d61eb000b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rank_fragment(fragment_vector_v3(frag), motif_vectors_v3)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tSLcxCPbKwfS",
        "outputId": "b091255c-2550-446b-f3af-36edfcf5dbe3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rank_fragment(fragment_vector_v4(frag), motif_vectors_v4)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YimLR-ZUTyP6",
        "outputId": "af29511a-e8fe-47dd-fb43-3e7ee654a23b"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "rank_fragment(fragment_vector_v5(frag, TOP_K_BIGRAMS), motif_vectors_v5)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "q3Do6MKJX8Fa",
        "outputId": "c41bef13-072f-4d44-fb68-6eff8fac9431"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Fragment to motifs Accuracy\n"
      ],
      "metadata": {
        "id": "Rabrhdy89JjQ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### V1 to V5 vector with motifs accuracy\n"
      ],
      "metadata": {
        "id": "cmnJs9aVBTdi"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "\tâ€¢\tFragment size = 32 symbols (1 bar)\n",
        "\tâ€¢\tIgnore fragments with >50% rests\n",
        "\tâ€¢\tEvaluate:\n",
        "\tâ€¢\tCosine (V1â€“V5)\n",
        "\tâ€¢\tLogReg (V1â€“V5)\n"
      ],
      "metadata": {
        "id": "LHy7Z1jA9SSB"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def extract_non_overlapping_fragments(\n",
        "    songs,\n",
        "    window_size=32,\n",
        "    rest_threshold=0.5,\n",
        "    strip_octave=True\n",
        "):\n",
        "    fragments = []\n",
        "\n",
        "    for s in songs:\n",
        "        motif = s[\"motif\"]\n",
        "        raw_seq = s[\"sequence\"]\n",
        "\n",
        "        # Convert to pitch symbols (remove rests automatically)\n",
        "        symbols = extract_symbols(raw_seq, strip_octave=strip_octave)\n",
        "\n",
        "        # Non-overlapping windows\n",
        "        for i in range(0, len(raw_seq), window_size):\n",
        "            window_tokens = raw_seq[i:i+window_size]\n",
        "\n",
        "            if len(window_tokens) < window_size:\n",
        "                continue\n",
        "\n",
        "            # Rest ratio check\n",
        "            rest_count = sum(1 for t in window_tokens if t == \"----\")\n",
        "            if rest_count / window_size > rest_threshold:\n",
        "                continue\n",
        "\n",
        "            # Convert to symbols\n",
        "            frag_symbols = extract_symbols(window_tokens, strip_octave=strip_octave)\n",
        "\n",
        "            if len(frag_symbols) < 5:  # safety guard\n",
        "                continue\n",
        "\n",
        "            fragments.append((frag_symbols, motif))\n",
        "\n",
        "    return fragments"
      ],
      "metadata": {
        "id": "lG73__Q89NkF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def fragment_cosine_evaluation(\n",
        "    fragments,\n",
        "    motif_vectors,\n",
        "    fragment_vector_fn,\n",
        "    extra_args=None\n",
        "):\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    for symbols, true_motif in fragments:\n",
        "\n",
        "        if extra_args:\n",
        "            x = fragment_vector_fn(symbols, *extra_args)\n",
        "        else:\n",
        "            x = fragment_vector_fn(symbols)\n",
        "\n",
        "        sims = {\n",
        "            m: cosine_similarity(\n",
        "                x.reshape(1, -1),\n",
        "                vec.reshape(1, -1)\n",
        "            )[0, 0]\n",
        "            for m, vec in motif_vectors.items()\n",
        "        }\n",
        "\n",
        "        pred = max(sims.items(), key=lambda x: x[1])[0]\n",
        "\n",
        "        y_true.append(true_motif)\n",
        "        y_pred.append(pred)\n",
        "\n",
        "    labels = sorted(set(y_true))\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "\n",
        "    return round(acc, 4), pd.DataFrame(cm, index=labels, columns=labels)"
      ],
      "metadata": {
        "id": "DWnVl-J89WQl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MOTIFS_USED = [\"à¸¥à¸²à¸§\", \"à¹€à¸‚à¸¡à¸£\", \"à¹à¸‚à¸\"]\n",
        "\n",
        "fragments = extract_non_overlapping_fragments(\n",
        "    songs,\n",
        "    window_size=32,\n",
        "    rest_threshold=0.5\n",
        ")\n",
        "\n",
        "# V1\n",
        "acc_v1_frag, cm_v1_frag = fragment_cosine_evaluation(\n",
        "    fragments,\n",
        "    motif_vectors_v1,\n",
        "    fragment_vector_v1\n",
        ")\n",
        "\n",
        "# V2\n",
        "acc_v2_frag, cm_v2_frag = fragment_cosine_evaluation(\n",
        "    fragments,\n",
        "    motif_vectors_v2,\n",
        "    fragment_vector_v2\n",
        ")\n",
        "\n",
        "# V3\n",
        "acc_v3_frag, cm_v3_frag = fragment_cosine_evaluation(\n",
        "    fragments,\n",
        "    motif_vectors_v3,\n",
        "    fragment_vector_v3\n",
        ")\n",
        "\n",
        "# V4\n",
        "acc_v4_frag, cm_v4_frag = fragment_cosine_evaluation(\n",
        "    fragments,\n",
        "    motif_vectors_v4,\n",
        "    fragment_vector_v4\n",
        ")\n",
        "\n",
        "# V5\n",
        "acc_v5_frag, cm_v5_frag = fragment_cosine_evaluation(\n",
        "    fragments,\n",
        "    motif_vectors_v5,\n",
        "    fragment_vector_v5,\n",
        "    extra_args=[TOP_K_BIGRAMS]\n",
        ")\n",
        "\n",
        "acc_v1_frag, acc_v2_frag, acc_v3_frag, acc_v4_frag, acc_v5_frag"
      ],
      "metadata": {
        "id": "LAvD9BpA9Zig",
        "outputId": "f39efe37-1891-439a-d3f7-74979a98490b",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LogReg\n"
      ],
      "metadata": {
        "id": "4NfsoLRvBXzZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "fragments = extract_non_overlapping_fragments(\n",
        "    songs,\n",
        "    window_size=32,\n",
        "    rest_threshold=0.5,\n",
        "    strip_octave=True\n",
        ")"
      ],
      "metadata": {
        "id": "zU0FS2fTBZmg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "for i, (symbols, motif) in enumerate(fragments[:5]):\n",
        "    print(f\"Fragment {i} | Motif: {motif}\")\n",
        "    print(symbols)\n",
        "    print(\"-\" * 40)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LoSQcx0CB84h",
        "outputId": "1313b10c-7132-4ca0-f732-9c508c82e83e"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def fragment_logreg_evaluation(\n",
        "    fragments,\n",
        "    fragment_vector_fn\n",
        "):\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    for i, (test_symbols, test_label) in enumerate(fragments):\n",
        "\n",
        "        # --- split ---\n",
        "        train_data = [\n",
        "            (symbols, label)\n",
        "            for j, (symbols, label) in enumerate(fragments)\n",
        "            if j != i\n",
        "        ]\n",
        "\n",
        "        # --- build train ---\n",
        "        X_train = np.vstack([\n",
        "            fragment_vector_fn(symbols)\n",
        "            for symbols, _ in train_data\n",
        "        ])\n",
        "        y_train = [label for _, label in train_data]\n",
        "\n",
        "        # --- build test ---\n",
        "        X_test = fragment_vector_fn(test_symbols).reshape(1, -1)\n",
        "\n",
        "        # --- train ---\n",
        "        clf = LogisticRegression(\n",
        "            solver=\"lbfgs\",\n",
        "            max_iter=1000\n",
        "        )\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        # --- predict ---\n",
        "        pred = clf.predict(X_test)[0]\n",
        "\n",
        "        y_true.append(test_label)\n",
        "        y_pred.append(pred)\n",
        "\n",
        "    labels = sorted(set(y_true))\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "\n",
        "    return round(acc, 4), pd.DataFrame(cm, index=labels, columns=labels)"
      ],
      "metadata": {
        "id": "NwxpuelHCRPP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_f_v1, cm_f_v1 = fragment_logreg_evaluation(\n",
        "    fragments,\n",
        "    fragment_vector_v1\n",
        ")\n",
        "\n",
        "acc_f_v2, cm_f_v2 = fragment_logreg_evaluation(\n",
        "    fragments,\n",
        "    fragment_vector_v2\n",
        ")\n",
        "\n",
        "acc_f_v3, cm_f_v3 = fragment_logreg_evaluation(\n",
        "    fragments,\n",
        "    fragment_vector_v3\n",
        ")\n",
        "\n",
        "acc_f_v4, cm_f_v4 = fragment_logreg_evaluation(\n",
        "    fragments,\n",
        "    fragment_vector_v4\n",
        ")\n",
        "\n",
        "acc_f_v5, cm_f_v5 = fragment_logreg_evaluation(\n",
        "    fragments,\n",
        "    lambda s: fragment_vector_v5(s, TOP_K_BIGRAMS)\n",
        ")\n",
        "\n",
        "acc_f_v1, acc_f_v2, acc_f_v3, acc_f_v4, acc_f_v5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YPrQVrR1CSjG",
        "outputId": "0e4bf5e4-ecf6-4dd8-ff4b-913ad259f54c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Song to motifs Accuracy\n"
      ],
      "metadata": {
        "id": "jhZbF1KVPePP"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "**LOSO = Leave-One-Song-Out.**\n",
        "\n",
        "\tâ€¢\tHold one song out as test\n",
        "\tâ€¢\tTrain on all remaining songs\n",
        "\tâ€¢\tPredict the held-out song\n",
        "\tâ€¢\tRepeat for every song\n",
        "\tâ€¢\tAverage the results\n"
      ],
      "metadata": {
        "id": "lULXExTSRaAb"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "# ===== Song-level vector wrappers =====\n",
        "\n",
        "def song_vector_v1(song):\n",
        "    return motif_vector_v1([song], song[\"motif\"])\n",
        "\n",
        "def song_vector_v2(song):\n",
        "    return motif_vector_v2([song], song[\"motif\"])\n",
        "\n",
        "def song_vector_v3(song):\n",
        "    return motif_vector_v3([song], song[\"motif\"])\n",
        "\n",
        "def song_vector_v4(song):\n",
        "    return motif_vector_v4([song], song[\"motif\"])\n",
        "\n",
        "def song_vector_v5(song, top_k_bigrams):\n",
        "    return motif_vector_v5([song], song[\"motif\"], top_k_bigrams)"
      ],
      "metadata": {
        "id": "Oz3L42vBT534"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics.pairwise import cosine_similarity\n",
        "from sklearn.metrics import confusion_matrix, accuracy_score\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def loso_cosine_evaluation(\n",
        "    songs,\n",
        "    song_vector_fn,\n",
        "    motifs_used,\n",
        "    extra_args=None\n",
        "):\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    for i, test_song in enumerate(songs):\n",
        "        if test_song[\"motif\"] not in motifs_used:\n",
        "            continue\n",
        "\n",
        "        # split\n",
        "        train_songs = [\n",
        "            s for j, s in enumerate(songs)\n",
        "            if j != i and s[\"motif\"] in motifs_used\n",
        "        ]\n",
        "\n",
        "        # build motif centroids from TRAIN only\n",
        "        centroids = {}\n",
        "        for m in motifs_used:\n",
        "            vecs = []\n",
        "            for s in train_songs:\n",
        "                if s[\"motif\"] == m:\n",
        "                    if extra_args:\n",
        "                        vecs.append(song_vector_fn(s, *extra_args))\n",
        "                    else:\n",
        "                        vecs.append(song_vector_fn(s))\n",
        "            centroids[m] = np.mean(np.vstack(vecs), axis=0)\n",
        "\n",
        "        # test vector\n",
        "        if extra_args:\n",
        "            x_test = song_vector_fn(test_song, *extra_args)\n",
        "        else:\n",
        "            x_test = song_vector_fn(test_song)\n",
        "\n",
        "        # cosine similarity\n",
        "        sims = {\n",
        "            m: cosine_similarity(\n",
        "                x_test.reshape(1, -1),\n",
        "                centroids[m].reshape(1, -1)\n",
        "            )[0, 0]\n",
        "            for m in centroids\n",
        "        }\n",
        "\n",
        "        pred = max(sims.items(), key=lambda x: x[1])[0]\n",
        "\n",
        "        y_true.append(test_song[\"motif\"])\n",
        "        y_pred.append(pred)\n",
        "\n",
        "    labels = sorted(set(y_true))\n",
        "    # acc = accuracy_score(y_true, y_pred)\n",
        "    acc = round(accuracy_score(y_true, y_pred), 4)\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "\n",
        "    return acc, pd.DataFrame(cm, index=labels, columns=labels)"
      ],
      "metadata": {
        "id": "gCqppH7_T6oc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "---\n"
      ],
      "metadata": {
        "id": "dDF9oXveUBop"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "MOTIFS_EVAL = [\"à¸¥à¸²à¸§\", \"à¹€à¸‚à¸¡à¸£\", \"à¹à¸‚à¸\"]"
      ],
      "metadata": {
        "id": "LhDTe28MT_K0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_v1, cm_v1 = loso_cosine_evaluation(\n",
        "    songs,\n",
        "    song_vector_v1,\n",
        "    MOTIFS_EVAL\n",
        ")\n",
        "acc_v1, cm_v1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VqxpooCcUC1t",
        "outputId": "54d7dde7-adb2-4723-9926-bef266d87e95"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_v2, cm_v2 = loso_cosine_evaluation(\n",
        "    songs,\n",
        "    song_vector_v2,\n",
        "    MOTIFS_EVAL\n",
        ")\n",
        "acc_v2, cm_v2"
      ],
      "metadata": {
        "id": "5Z-IUdcuUMA-",
        "outputId": "7341f388-b34e-458f-bb87-98270a0f5a87",
        "colab": {
          "base_uri": "https://localhost:8080/"
        }
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_v3, cm_v3 = loso_cosine_evaluation(\n",
        "    songs,\n",
        "    song_vector_v3,\n",
        "    MOTIFS_EVAL\n",
        ")\n",
        "acc_v3, cm_v3"
      ],
      "metadata": {
        "id": "g8ind53NUOQu",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "4e990023-8c02-4809-b20d-e9593700d752"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_v4, cm_v4 = loso_cosine_evaluation(\n",
        "    songs,\n",
        "    song_vector_v4,\n",
        "    MOTIFS_EVAL\n",
        ")\n",
        "acc_v4, cm_v4"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XW13N6-1hXeM",
        "outputId": "392ef861-5da9-4a6a-9005-b00eb7bda632"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_v5, cm_v5 = loso_cosine_evaluation(\n",
        "    songs,\n",
        "    song_vector_v5,\n",
        "    MOTIFS_EVAL,\n",
        "    extra_args=[TOP_K_BIGRAMS]\n",
        ")\n",
        "acc_v5, cm_v5"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "O-0V3bx-hz5o",
        "outputId": "0a6bb638-dc77-4197-910e-44a1bb747494"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### LogReg\n"
      ],
      "metadata": {
        "id": "2SgUU7gnj25c"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Baseline Classification Setup (Logistic Regression)\n",
        "\n",
        "**Unit of analysis:**  \n",
        "- Whole song\n",
        "\n",
        "**Label:**  \n",
        "- Motif (e.g. à¸¥à¸²à¸§, à¹€à¸‚à¸¡à¸£, à¹à¸‚à¸)\n",
        "\n",
        "**Evaluation protocol:**  \n",
        "- LOSO (Leave-One-Song-Out)\n",
        "\n",
        "\n",
        "For Logistic Regression:\n",
        "\n",
        "- **X**: matrix of song-level feature vectors  \n",
        "  - Shape: *(num_songs, feature_dim)*\n",
        "\n",
        "- **y**: motif labels  \n",
        "  - Shape: *(num_songs,)*\n",
        "\n",
        "#### LOSO evaluation procedure\n",
        "\n",
        "For each iteration:\n",
        "\n",
        "1. Hold **one song** out as the test sample  \n",
        "2. Train the model on **all remaining songs**  \n",
        "3. Predict the motif of the held-out song  \n",
        "4. Repeat until every song has been used as test once  \n",
        "\n",
        "**Final metrics:**  \n",
        "- Overall accuracy  \n",
        "- Confusion matrix\n",
        "\n"
      ],
      "metadata": {
        "id": "DpdQgmbAkztF"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def song_vector_v1(song):\n",
        "    symbols = song[\"symbol_sequence\"]\n",
        "    return np.array(\n",
        "        pitch_vector_from_symbols(symbols)\n",
        "        + interval_vector_from_symbols(symbols)\n",
        "    )\n",
        "\n",
        "def song_vector_v2(song):\n",
        "    symbols = song[\"symbol_sequence\"]\n",
        "    return np.concatenate([\n",
        "        song_vector_v1(song),\n",
        "        directional_interval_stats(symbols)     # +3D\n",
        "    ])\n",
        "\n",
        "def song_vector_v3(song):\n",
        "    symbols = song[\"symbol_sequence\"]\n",
        "    return np.concatenate([\n",
        "        song_vector_v2(song),\n",
        "        [interval_entropy(symbols)]              # +1D\n",
        "    ])\n",
        "\n",
        "def song_vector_v4(song):\n",
        "    symbols = song[\"symbol_sequence\"]\n",
        "    return np.concatenate([\n",
        "        song_vector_v3(song),\n",
        "        [pitch_class_entropy(symbols)]           # +1D\n",
        "    ])\n",
        "\n",
        "def song_vector_v5(song, top_k_bigrams):\n",
        "    symbols = song[\"symbol_sequence\"]\n",
        "    return np.concatenate([\n",
        "        song_vector_v4(song),\n",
        "        bigram_vector_from_symbols(symbols, top_k_bigrams)\n",
        "    ])\n"
      ],
      "metadata": {
        "id": "08jkzx45j39l"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score, confusion_matrix\n",
        "import numpy as np\n",
        "import pandas as pd\n",
        "\n",
        "def loso_logreg_evaluation(\n",
        "    songs,\n",
        "    song_vector_fn,\n",
        "    motifs_used\n",
        "):\n",
        "    y_true, y_pred = [], []\n",
        "\n",
        "    for i, test_song in enumerate(songs):\n",
        "        if test_song[\"motif\"] not in motifs_used:\n",
        "            continue\n",
        "\n",
        "        # --- split ---\n",
        "        train_songs = [\n",
        "            s for j, s in enumerate(songs)\n",
        "            if j != i and s[\"motif\"] in motifs_used\n",
        "        ]\n",
        "\n",
        "        # --- build train data ---\n",
        "        X_train = np.vstack([song_vector_fn(s) for s in train_songs])\n",
        "        y_train = [s[\"motif\"] for s in train_songs]\n",
        "\n",
        "        # --- build test sample ---\n",
        "        X_test = song_vector_fn(test_song).reshape(1, -1)\n",
        "\n",
        "        # --- train ---\n",
        "        clf = LogisticRegression(\n",
        "            multi_class=\"auto\",\n",
        "            solver=\"lbfgs\",\n",
        "            max_iter=1000\n",
        "        )\n",
        "        clf.fit(X_train, y_train)\n",
        "\n",
        "        # --- predict ---\n",
        "        pred = clf.predict(X_test)[0]\n",
        "\n",
        "        y_true.append(test_song[\"motif\"])\n",
        "        y_pred.append(pred)\n",
        "\n",
        "    labels = sorted(set(y_true))\n",
        "    acc = accuracy_score(y_true, y_pred)\n",
        "    cm = confusion_matrix(y_true, y_pred, labels=labels)\n",
        "\n",
        "    return round(acc, 4), pd.DataFrame(cm, index=labels, columns=labels)"
      ],
      "metadata": {
        "id": "B2TP9EoPm-b_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "MOTIFS_USED = [\"à¸¥à¸²à¸§\", \"à¹€à¸‚à¸¡à¸£\", \"à¹à¸‚à¸\"]\n",
        "\n",
        "acc_v1, cm_v1 = loso_logreg_evaluation(\n",
        "    songs,\n",
        "    song_vector_v1,\n",
        "    MOTIFS_USED\n",
        ")\n",
        "\n",
        "acc_v1, cm_v1"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gwxYUHGQnFSh",
        "outputId": "03d92e3c-e54f-487a-b339-b42924bcf50f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "acc_v2, cm_v2 = loso_logreg_evaluation(songs, song_vector_v2, MOTIFS_USED)\n",
        "acc_v3, cm_v3 = loso_logreg_evaluation(songs, song_vector_v3, MOTIFS_USED)\n",
        "acc_v4, cm_v4 = loso_logreg_evaluation(songs, song_vector_v4, MOTIFS_USED)\n",
        "\n",
        "acc_v5, cm_v5 = loso_logreg_evaluation(\n",
        "    songs,\n",
        "    lambda s: song_vector_v5(s, TOP_K_BIGRAMS),\n",
        "    MOTIFS_USED\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "fOkzirJko095",
        "outputId": "74a440e5-70d4-4fc2-c779-f106565b481f"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "df_acc = pd.DataFrame([\n",
        "    (\"V1\", acc_v1),\n",
        "    (\"V2\", acc_v2),\n",
        "    (\"V3\", acc_v3),\n",
        "    (\"V4\", acc_v4),\n",
        "    (\"V5\", acc_v5),\n",
        "], columns=[\"Version\", \"LOSO Accuracy\"])\n",
        "\n",
        "df_acc"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 206
        },
        "id": "bh9oP6MwrhW8",
        "outputId": "31b8cbaa-b1f9-4b1b-d681-59b1777b5836"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "\tâ€¢\tV1 strong baseline (0.625) â†’ pitch + interval already capture most signal\n",
        "\tâ€¢\tV2â€“V4 drop slightly â†’ added features introduce noise under very small data\n",
        "\tâ€¢\tV5 improves best (0.6875) â†’ order information (bigrams) actually helps\n",
        "\n",
        "  More features â‰  better performance under low-data; sequence information matters more than higher-order statistics.\n"
      ],
      "metadata": {
        "id": "Flq3DTVYJrML"
      }
    }
  ]
}
